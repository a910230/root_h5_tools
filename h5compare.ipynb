{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def get_nj(file):\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        nj = f[\"INPUTS/Source/MASK\"][...].sum(axis=1)\n",
    "    return nj\n",
    "\n",
    "def score(ans1, ans2):\n",
    "    set1 = {frozenset(row) for row in ans1.reshape(3, 2)}\n",
    "    set2 = {frozenset(row) for row in ans2.reshape(3, 2)}\n",
    "    return sum([1 for p in set1 if p in set2])\n",
    "\n",
    "def compare_if_3h(ans_test, ans_pred, nj, nj_target):\n",
    "    if nj_target == 8:\n",
    "        mask = (ans_test != -1).all(axis=1) & (nj >= 8)\n",
    "    else:\n",
    "        mask = (ans_test != -1).all(axis=1) & (nj == nj_target)\n",
    "\n",
    "    masked_ans_test = ans_test[mask]\n",
    "    masked_ans_pred = ans_pred[mask]\n",
    "    \n",
    "    compare = np.array([score(masked_ans_test[i], masked_ans_pred[i]) for i in range(len(masked_ans_test))])\n",
    "    return compare\n",
    "\n",
    "def get_match_answers(test_file, predict_file): # no sort\n",
    "    with h5py.File(test_file, \"r\") as f_test:\n",
    "        b0_test = f_test[\"TARGETS/h1/b1\"][...]\n",
    "        b1_test = f_test[\"TARGETS/h1/b2\"][...]\n",
    "        b2_test = f_test[\"TARGETS/h2/b1\"][...]\n",
    "        b3_test = f_test[\"TARGETS/h2/b2\"][...]\n",
    "        b4_test = f_test[\"TARGETS/h3/b1\"][...]\n",
    "        b5_test = f_test[\"TARGETS/h3/b2\"][...]\n",
    "    ans_test = np.array((b0_test, b1_test, b2_test, b3_test, b4_test, b5_test)).transpose()\n",
    "    ans_test[:,0:2].sort(axis=1)\n",
    "    ans_test[:,2:4].sort(axis=1)\n",
    "    ans_test[:,4:6].sort(axis=1)\n",
    "\n",
    "    with h5py.File(predict_file, \"r\") as f_pred:\n",
    "        b0_pred = f_pred[\"SpecialKey.Targets/h1/b1\"][...]\n",
    "        b1_pred = f_pred[\"SpecialKey.Targets/h1/b2\"][...]\n",
    "        b2_pred = f_pred[\"SpecialKey.Targets/h2/b1\"][...]\n",
    "        b3_pred = f_pred[\"SpecialKey.Targets/h2/b2\"][...]\n",
    "        b4_pred = f_pred[\"SpecialKey.Targets/h3/b1\"][...]\n",
    "        b5_pred = f_pred[\"SpecialKey.Targets/h3/b2\"][...]\n",
    "    ans_pred = np.array((b0_pred, b1_pred, b2_pred, b3_pred, b4_pred, b5_pred)).transpose()\n",
    "    ans_pred[:,0:2].sort(axis=1)\n",
    "    ans_pred[:,2:4].sort(axis=1)\n",
    "    ans_pred[:,4:6].sort(axis=1)\n",
    "\n",
    "    return ans_test, ans_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2510321967.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[72], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    p =\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "file1 = \"/home/dilatino/root_to_h5/test/3h_1500_1000_4b_test_27052.h5\"\n",
    "file2 = \"/home/dilatino/root_to_h5/test/3h_1500_1000_4b_test_27052_predict_50k.h5\"\n",
    "\n",
    "ans_test, ans_pred = get_match_answers(file1, file2)\n",
    "nj = get_nj(file1)\n",
    "count = []\n",
    "for nj_target in range(6, 9):\n",
    "    scores = compare_if_3h(ans_test, ans_pred, nj, nj_target)\n",
    "    count.append([int((scores == i).sum()) for i in range(3, -1, -1)])\n",
    "\n",
    "count = np.array(count)\n",
    "count = np.concat((count.sum(axis=1)[:, np.newaxis], count), axis=1)\n",
    "count = np.concat((count, count.sum(axis=0)[np.newaxis]))\n",
    "print(count)\n",
    "\n",
    "rate = np.concat(((count[:, 0] / count[3, 0])[:, np.newaxis], count[:, 1:] / count[:, 0][:,np.newaxis]), axis=1)\n",
    "rate = np.concat((rate, (np.inner(rate, np.array([0, 3, 2, 1, 0])) / 3)[:, np.newaxis]), axis=1)\n",
    "print(p)\n",
    "np.set_printoptions(precision=3)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7520700872393908\n",
      "0.8550971618474714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "with h5py.File(file1, 'r') as f:\n",
    "    signal_test = f[\"CLASSIFICATIONS/EVENT/signal\"][...]        \n",
    "\n",
    "with h5py.File(file2, 'r') as f:\n",
    "    signal = f[\"SpecialKey.Classifications/EVENT/signal\"][...]\n",
    "signal_pred = signal[:,0] < signal[:,1]\n",
    "\n",
    "acc = accuracy_score(signal_test, signal_pred)\n",
    "auc = roc_auc_score(signal_test, signal[:, 1])\n",
    "print(acc)\n",
    "print(auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50k prediction\n",
    "acc = 0.752\n",
    "auc = 0.855\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makkapakka3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
